# Data lakes with spark

## Usage
 1. Launch an EMR cluster.
 2. Open a Jupyter notebook from the console.
 3. Copy the codes from `etl.py` to the notebook and run the function `etl()`. You can pass `output_data` as a parameter to store the data in your own S3 bucket.